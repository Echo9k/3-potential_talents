{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQRTvAOuIh6d"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IfcoMcFoIkL4",
    "tags": []
   },
   "source": [
    "## 1. Importing neccessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8BhQXTijINtP"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pprint\n",
    "import random\n",
    "\n",
    "import re\n",
    "\n",
    "import tensorflow as tf\n",
    "import transformers\n",
    "\n",
    "import spacy\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJuXDxUMIhbh",
    "tags": []
   },
   "source": [
    "## 2. Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "-9zetYhdIyOd",
    "outputId": "4028d00c-5786-42e8-c0b3-1338e563791b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Native English Teacher at EPIK (English Program in Korea)</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>People Development Coordinator at Ryan</td>\n",
       "      <td>Denton, Texas</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>İzmir, Türkiye</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  \\\n",
       "0   1   \n",
       "1   2   \n",
       "2   3   \n",
       "3   4   \n",
       "4   5   \n",
       "\n",
       "                                                                                                  job_title  \\\n",
       "0  2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional   \n",
       "1                                                 Native English Teacher at EPIK (English Program in Korea)   \n",
       "2                                                                     Aspiring Human Resources Professional   \n",
       "3                                                                    People Development Coordinator at Ryan   \n",
       "4                                                           Advisory Board Member at Celal Bayar University   \n",
       "\n",
       "                              location connection  fit  \n",
       "0                       Houston, Texas         85  NaN  \n",
       "1                               Kanada      500+   NaN  \n",
       "2  Raleigh-Durham, North Carolina Area         44  NaN  \n",
       "3                        Denton, Texas      500+   NaN  \n",
       "4                       İzmir, Türkiye      500+   NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_original = pd.read_csv('../data/raw/data.csv')\n",
    "dataset_original.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ZxTA2xYJxMd",
    "tags": []
   },
   "source": [
    "# Inspecting & Cleaning the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "YWmbO7ciKAO_"
   },
   "outputs": [],
   "source": [
    "dataset_cleaned_temp = dataset_original.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lPCcKoVxLS9Z",
    "outputId": "eed77581-73b0-4d5d-9fce-3372e4399d3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 104 entries, 0 to 103\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   id          104 non-null    int64  \n",
      " 1   job_title   104 non-null    object \n",
      " 2   location    104 non-null    object \n",
      " 3   connection  104 non-null    object \n",
      " 4   fit         0 non-null      float64\n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 4.2+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset_cleaned_temp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>104.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>52.500000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>30.166206</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>26.750000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>52.500000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>78.250000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>104.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  fit\n",
       "count  104.000000  0.0\n",
       "mean    52.500000  NaN\n",
       "std     30.166206  NaN\n",
       "min      1.000000  NaN\n",
       "25%     26.750000  NaN\n",
       "50%     52.500000  NaN\n",
       "75%     78.250000  NaN\n",
       "max    104.000000  NaN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_cleaned_temp.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LVstE0AtLLvL"
   },
   "source": [
    "### Checking missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              0\n",
       "job_title       0\n",
       "location        0\n",
       "connection      0\n",
       "fit           104\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_cleaned_temp.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_cleaned_temp.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove unnecessary words & Replace abbreviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional                 7\n",
       "Aspiring Human Resources Professional                                                                                    7\n",
       "Student at Humber College and Aspiring Human Resources Generalist                                                        7\n",
       "People Development Coordinator at Ryan                                                                                   6\n",
       "Native English Teacher at EPIK (English Program in Korea)                                                                5\n",
       "Aspiring Human Resources Specialist                                                                                      5\n",
       "HR Senior Specialist                                                                                                     5\n",
       "Student at Chapman University                                                                                            4\n",
       "SVP, CHRO, Marketing & Communications, CSR Officer | ENGIE | Houston | The Woodlands | Energy | GPHR | SPHR              4\n",
       "Human Resources Coordinator at InterContinental Buckhead Atlanta                                                         4\n",
       "Seeking Human Resources HRIS and Generalist Positions                                                                    4\n",
       "Advisory Board Member at Celal Bayar University                                                                          4\n",
       "Aspiring Human Resources Management student seeking an internship                                                        2\n",
       "Seeking Human Resources Opportunities                                                                                    2\n",
       "Seeking Human  Resources Opportunities. Open to travel and relocation.                                                   1\n",
       "Bachelor of Science in Biology from Victoria University of Wellington                                                    1\n",
       "Human Resources Management Major                                                                                         1\n",
       "Director Human Resources  at EY                                                                                          1\n",
       "Undergraduate Research Assistant at Styczynski Lab                                                                       1\n",
       "Lead Official at Western Illinois University                                                                             1\n",
       "Seeking employment opportunities within Customer Service or Patient Care                                                 1\n",
       "Admissions Representative at Community medical center long beach                                                         1\n",
       "Human Resources Generalist at Loparex                                                                                    1\n",
       "Student at Westfield State University                                                                                    1\n",
       "Student at Indiana University Kokomo - Business Management - \\nRetail Manager at Delphi Hardware and Paint               1\n",
       "Student                                                                                                                  1\n",
       "Seeking Human Resources Position                                                                                         1\n",
       "Aspiring Human Resources Manager | Graduating May 2020 | Seeking an Entry-Level Human Resources Position in St. Louis    1\n",
       "RRP Brand Portfolio Executive at JTI (Japan Tobacco International)                                                       1\n",
       "Business Intelligence and Analytics at Travelers                                                                         1\n",
       "Always set them up for Success                                                                                           1\n",
       "Information Systems Specialist and Programmer with a love for data and organization.                                     1\n",
       "Human Resources Generalist at Schwan's                                                                                   1\n",
       "Human Resources professional for the world leader in GIS software                                                        1\n",
       "Aspiring Human Resources Manager, seeking internship in Human Resources.                                                 1\n",
       "Experienced Retail Manager and aspiring Human Resources Professional                                                     1\n",
       "Human Resources, Staffing and Recruiting Professional                                                                    1\n",
       "Human Resources Specialist at Luxottica                                                                                  1\n",
       "Director of Human Resources North America, Groupe Beneteau                                                               1\n",
       "Retired Army National Guard Recruiter, office manager,  seeking a position in Human Resources.                           1\n",
       "Human Resources Generalist at ScottMadden, Inc.                                                                          1\n",
       "Business Management Major and Aspiring Human Resources Manager                                                           1\n",
       "Human Resources Professional                                                                                             1\n",
       "HR Manager at Endemol Shine North America                                                                                1\n",
       "Nortia Staffing is seeking Human Resources, Payroll & Administrative Professionals!!  (408) 709-2621                     1\n",
       "Aspiring Human Resources Professional | Passionate about helping to create an inclusive and engaging work environment    1\n",
       "Human Resources|\\nConflict Management|\\nPolicies & Procedures|Talent Management|Benefits & Compensation                  1\n",
       "Liberal Arts Major. Aspiring Human Resources Analyst.                                                                    1\n",
       "Junior MES Engineer| Information Systems                                                                                 1\n",
       "Senior Human Resources Business Partner at Heil Environmental                                                            1\n",
       "Aspiring Human Resources Professional | An energetic and Team-Focused Leader                                             1\n",
       "Director Of Administration at Excellence Logging                                                                         1\n",
       "Name: job_title, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_cleaned_temp['job_title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_nlp = spacy.load('en_core_web_sm')\n",
    "spacy_nlp.pipe_names\n",
    "\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbreviations_to_replace = {\n",
    "    'GPHR': 'Global Professional in Human Resources',\n",
    "    'CSR': 'Corporate Social Responsibility',\n",
    "    'MES': 'Manufacturing Execution Systems',\n",
    "    'SPHR': 'Senior Professional in Human Resources',\n",
    "    'SVP': 'Senior Vice President',\n",
    "    'GIS': 'Geographic Information System',\n",
    "    'RRP': 'Reduced Risk Products',\n",
    "    'CHRO': 'Chief Human Resources Officer',\n",
    "    'HRIS': 'Human resources information system',\n",
    "    'HR': 'Human resources',\n",
    "}\n",
    "\n",
    "def replace_abbreviations(sentence):\n",
    "    replaced_sentence = sentence\n",
    "    for abbreviation, replacement in abbreviations_to_replace.items():\n",
    "        # Create a regular expression pattern to match the whole word\n",
    "        pattern = r'\\b{}\\b'.format(re.escape(abbreviation))\n",
    "    \n",
    "        # Use re.sub() to replace the word in the sentence\n",
    "        replaced_sentence = re.sub(pattern, replacement, replaced_sentence, flags=re.IGNORECASE)\n",
    "\n",
    "    return replaced_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence(sentence):\n",
    "    # Remove special characters\n",
    "    new_sentence = re.sub(r'[+*,.|(){}&\\-\\']', '', sentence)\n",
    "\n",
    "    # Replce abbreviations\n",
    "    new_sentence = replace_abbreviations(new_sentence)\n",
    "    \n",
    "    words = new_sentence.split()\n",
    "    \n",
    "    # Stemming\n",
    "    stemmed_words = []\n",
    "    for word in words:\n",
    "        stemmed_words.append(stemmer.stem(word))\n",
    "        \n",
    "    # Lemmatization\n",
    "    lemmatized_words = []\n",
    "    doc = spacy_nlp(\" \".join(stemmed_words))\n",
    "    for token in doc:\n",
    "        if not token.is_stop:\n",
    "            lemmatized_words.append(token.lemma_)\n",
    "\n",
    "    return \" \".join(lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2019 ct bauer colleg busi graduat magna cum laud aspir human resourc profession\n",
      "1                                   nativ english teacher epik english program korea\n",
      "2                                                     aspir human resourc profession\n",
      "3                                                         peopl develop coordin ryan\n",
      "4                                           advisori board member celal bayar univer\n",
      "Name: job_title_cleaned, dtype: object\n"
     ]
    }
   ],
   "source": [
    "dataset_cleaned_temp['job_title_cleaned'] = dataset_cleaned_temp['job_title'].apply(clean_sentence)\n",
    "print(dataset_cleaned_temp['job_title_cleaned'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['care', 'passion', 'presid', 'scottmadden', 'energet', 'celal', 'employ', 'undergradu', 'compen', 'bachelor', 'generalist', 'engin', 'brand', 'western', 'buckhead', 'nortia', 'advisori', 'intellig', 'aspir', 'senior', 'servic', 'kokomo', 'engag', 'center', 'univer', 'japan', 'specialist', 'environment', 'woodland', 'recruit', 'wellington', 'ryan', 'softwar', 'administr', 'environ', 'patient', 'program', 'member', 'loui', 'manag', 'datum', 'north', 'develop', 'offic', 'excel', 'lab', 'epik', 'bayar', 'manufactur', 'market', 'magna', 'america', 'cum', 'group', 'indiana', 'corpor', 'intern', 'korea', 'inclus', 'humber', 'coordin', 'biolog', 'resourc', 'execut', 'colleg', '2020', 'offici', 'ct', 'help', 'art', 'human', 'travel', 'student', 'internship', 'portfolio', 'alway', '7092621', 'repre', 'houston', 'leader', 'log', 'staf', 'vice', 'nation', 'admiss', '!', 'beneteau', 'schwan', 'conflict', 'paint', 'organ', 'reloc', 'analyst', 'heil', 'liber', 'graduat', 'major', 'opportun', 'guard', 'illinoi', 'inc', 'work', 'st', 'univers', 'programm', 'social', 'luxottica', 'chapman', 'medic', 'hardwar', 'product', '408', 'managementbenefit', 'shine', 'custom', 'risk', 'nativ', 'armi', 'scienc', 'love', 'ey', 'retail', 'chief', 'energi', 'professional', 'system', 'teacher', 'profession', 'commun', 'long', 'research', 'open', 'loparex', '2019', 'global', 'tobacco', 'intercontinent', 'engi', 'geograph', 'partner', 'retir', 'world', 'styczynski', 'busi', 'board', 'respon', 'payrol', 'assist', 'english', 'victoria', 'analyt', 'lead', 'beach', 'set', 'reduc', 'teamfocus', 'experienc', 'junior', 'polici', 'delphi', 'bauer', 'inform', 'procedurestal', 'creat', 'westfield', 'peopl', 'posit', 'entrylevel', 'endemol', 'seek', 'laud', 'state', 'jti', 'director', 'success', 'atlanta']\n"
     ]
    }
   ],
   "source": [
    "print([*set(dataset_cleaned_temp[\"job_title_cleaned\"].str.split().agg(sum, axis = 0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "5bR931S7Laca"
   },
   "outputs": [],
   "source": [
    "dataset_cleaned = dataset_cleaned_temp.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UH5QdnRML6Fs",
    "tags": []
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_preprocessed = dataset_cleaned.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup BERT & Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01e18020603d44c2a91555233226941f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Roaming\\Python\\Python39\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\hp\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58f0a9c080b54109b8cefd8c73a209fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2254e1db9e34ee38270d63f405e1bf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ace7076093884d4cb3c87ae1699ad0b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, TFBertModel\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = TFBertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_embeddings(sentences):\n",
    "    embeddings = []\n",
    "    for sentence in sentences:\n",
    "        # Tokenize input sentence\n",
    "        encoded_inputs = bert_tokenizer(sentence, padding=True, truncation=True, return_tensors='tf')\n",
    "    \n",
    "        # Generate BERT embeddings\n",
    "        outputs = bert_model(encoded_inputs)\n",
    "        hidden_states = outputs.last_hidden_state\n",
    "\n",
    "        # Apply pooling strategy - averaging\n",
    "        pooled = tf.reduce_mean(hidden_states, axis=1)\n",
    "        embeddings.append(pooled.numpy().reshape(-1))\n",
    "    \n",
    "    return np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def encode_and_get_similarity(data, queries, search_columns, output_columns):\n",
    "    data = data.copy()\n",
    "    \n",
    "    embeddings = {}\n",
    "    queries_embeddings = []\n",
    "    \n",
    "    # without replacing the abbreviations with their full meaning, we will get very bad results\n",
    "    for index, query in enumerate(queries):\n",
    "        query = replace_abbreviations(query)\n",
    "        query = clean_sentence(query)\n",
    "        queries_embeddings.append(get_bert_embeddings([query]))\n",
    "        \n",
    "    queries_embeddings_mean = np.mean(queries_embeddings, axis=0)\n",
    "    # queries_embeddings_mean = get_bert_embeddings('Aspiring Human Resources Professional')\n",
    "\n",
    "    for index, column in enumerate(search_columns):\n",
    "        sentences = dataset_preprocessed[column].tolist()\n",
    "\n",
    "        # Encoding\n",
    "        embeddings[column] = get_bert_embeddings(sentences)\n",
    "\n",
    "        # Cosine Similarity\n",
    "        cosine_similarities = cosine_similarity(\n",
    "            queries_embeddings_mean,\n",
    "            embeddings[column]\n",
    "        )        \n",
    "        data[output_columns[index]] = cosine_similarities[0]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Queries/Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    # 'Aspiring Human Resources Professional',\n",
    "    'aspiring human resources',\n",
    "    'seeking human resources'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Embeddings & Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_preprocessed = encode_and_get_similarity(dataset_preprocessed, queries, ['job_title_cleaned'], ['bert_similarity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "      <th>job_title_cleaned</th>\n",
       "      <th>bert_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Aspiring Human Resources Specialist</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aspir human resourc specialist</td>\n",
       "      <td>0.918639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Aspiring Human Resources Specialist</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aspir human resourc specialist</td>\n",
       "      <td>0.918639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>60</td>\n",
       "      <td>Aspiring Human Resources Specialist</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aspir human resourc specialist</td>\n",
       "      <td>0.918639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>Aspiring Human Resources Specialist</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aspir human resourc specialist</td>\n",
       "      <td>0.918639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>Aspiring Human Resources Specialist</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aspir human resourc specialist</td>\n",
       "      <td>0.918639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>Seeking Human Resources Position</td>\n",
       "      <td>Las Vegas, Nevada Area</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>seek human resourc posit</td>\n",
       "      <td>0.899539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>68</td>\n",
       "      <td>Human Resources Specialist at Luxottica</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>human resourc specialist luxottica</td>\n",
       "      <td>0.890844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>88</td>\n",
       "      <td>Human Resources Management Major</td>\n",
       "      <td>Milpitas, California</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>human resourc manag major</td>\n",
       "      <td>0.883634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>101</td>\n",
       "      <td>Human Resources Generalist at Loparex</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>human resourc generalist loparex</td>\n",
       "      <td>0.867990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aspir human resourc profession</td>\n",
       "      <td>0.860986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aspir human resourc profession</td>\n",
       "      <td>0.860986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aspir human resourc profession</td>\n",
       "      <td>0.860986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Kokomo, Indiana Area</td>\n",
       "      <td>71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aspir human resourc profession</td>\n",
       "      <td>0.860986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aspir human resourc profession</td>\n",
       "      <td>0.860986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>58</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aspir human resourc profession</td>\n",
       "      <td>0.860986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aspir human resourc profession</td>\n",
       "      <td>0.860986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>89</td>\n",
       "      <td>Director Human Resources  at EY</td>\n",
       "      <td>Greater Atlanta Area</td>\n",
       "      <td>349</td>\n",
       "      <td>NaN</td>\n",
       "      <td>director human resourc ey</td>\n",
       "      <td>0.845359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>82</td>\n",
       "      <td>Aspiring Human Resources Professional | An energetic and Team-Focused Leader</td>\n",
       "      <td>Austin, Texas Area</td>\n",
       "      <td>174</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aspir human resourc profession energet teamfocus leader</td>\n",
       "      <td>0.839728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>HR Senior Specialist</td>\n",
       "      <td>San Francisco Bay Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>human resourc senior specialist</td>\n",
       "      <td>0.837753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>51</td>\n",
       "      <td>HR Senior Specialist</td>\n",
       "      <td>San Francisco Bay Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>human resourc senior specialist</td>\n",
       "      <td>0.837753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  \\\n",
       "23    24   \n",
       "5      6   \n",
       "59    60   \n",
       "35    36   \n",
       "48    49   \n",
       "98    99   \n",
       "67    68   \n",
       "87    88   \n",
       "100  101   \n",
       "20    21   \n",
       "32    33   \n",
       "16    17   \n",
       "96    97   \n",
       "45    46   \n",
       "57    58   \n",
       "2      3   \n",
       "88    89   \n",
       "81    82   \n",
       "25    26   \n",
       "50    51   \n",
       "\n",
       "                                                                        job_title  \\\n",
       "23                                            Aspiring Human Resources Specialist   \n",
       "5                                             Aspiring Human Resources Specialist   \n",
       "59                                            Aspiring Human Resources Specialist   \n",
       "35                                            Aspiring Human Resources Specialist   \n",
       "48                                            Aspiring Human Resources Specialist   \n",
       "98                                               Seeking Human Resources Position   \n",
       "67                                        Human Resources Specialist at Luxottica   \n",
       "87                                               Human Resources Management Major   \n",
       "100                                         Human Resources Generalist at Loparex   \n",
       "20                                          Aspiring Human Resources Professional   \n",
       "32                                          Aspiring Human Resources Professional   \n",
       "16                                          Aspiring Human Resources Professional   \n",
       "96                                          Aspiring Human Resources Professional   \n",
       "45                                          Aspiring Human Resources Professional   \n",
       "57                                          Aspiring Human Resources Professional   \n",
       "2                                           Aspiring Human Resources Professional   \n",
       "88                                                Director Human Resources  at EY   \n",
       "81   Aspiring Human Resources Professional | An energetic and Team-Focused Leader   \n",
       "25                                                           HR Senior Specialist   \n",
       "50                                                           HR Senior Specialist   \n",
       "\n",
       "                                location connection  fit  \\\n",
       "23            Greater New York City Area          1  NaN   \n",
       "5             Greater New York City Area          1  NaN   \n",
       "59            Greater New York City Area          1  NaN   \n",
       "35            Greater New York City Area          1  NaN   \n",
       "48            Greater New York City Area          1  NaN   \n",
       "98                Las Vegas, Nevada Area         48  NaN   \n",
       "67            Greater New York City Area      500+   NaN   \n",
       "87                  Milpitas, California         18  NaN   \n",
       "100  Raleigh-Durham, North Carolina Area      500+   NaN   \n",
       "20   Raleigh-Durham, North Carolina Area         44  NaN   \n",
       "32   Raleigh-Durham, North Carolina Area         44  NaN   \n",
       "16   Raleigh-Durham, North Carolina Area         44  NaN   \n",
       "96                  Kokomo, Indiana Area         71  NaN   \n",
       "45   Raleigh-Durham, North Carolina Area         44  NaN   \n",
       "57   Raleigh-Durham, North Carolina Area         44  NaN   \n",
       "2    Raleigh-Durham, North Carolina Area         44  NaN   \n",
       "88                  Greater Atlanta Area        349  NaN   \n",
       "81                    Austin, Texas Area        174  NaN   \n",
       "25                San Francisco Bay Area      500+   NaN   \n",
       "50                San Francisco Bay Area      500+   NaN   \n",
       "\n",
       "                                           job_title_cleaned  bert_similarity  \n",
       "23                            aspir human resourc specialist         0.918639  \n",
       "5                             aspir human resourc specialist         0.918639  \n",
       "59                            aspir human resourc specialist         0.918639  \n",
       "35                            aspir human resourc specialist         0.918639  \n",
       "48                            aspir human resourc specialist         0.918639  \n",
       "98                                  seek human resourc posit         0.899539  \n",
       "67                        human resourc specialist luxottica         0.890844  \n",
       "87                                 human resourc manag major         0.883634  \n",
       "100                         human resourc generalist loparex         0.867990  \n",
       "20                            aspir human resourc profession         0.860986  \n",
       "32                            aspir human resourc profession         0.860986  \n",
       "16                            aspir human resourc profession         0.860986  \n",
       "96                            aspir human resourc profession         0.860986  \n",
       "45                            aspir human resourc profession         0.860986  \n",
       "57                            aspir human resourc profession         0.860986  \n",
       "2                             aspir human resourc profession         0.860986  \n",
       "88                                 director human resourc ey         0.845359  \n",
       "81   aspir human resourc profession energet teamfocus leader         0.839728  \n",
       "25                           human resourc senior specialist         0.837753  \n",
       "50                           human resourc senior specialist         0.837753  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_preprocessed.sort_values(by='bert_similarity', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starred Candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mark them as favorite/bookmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starred_ids = [int(item) for item in input(\"Enter the ids of the candidates you want to star (separate by spaces): \").split()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Rank (Re-Rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- similar to bookmark\n",
    "- First way:  Marging the keypharse and the starred title\n",
    "- Second way: one more column of scores (starred), use the starred job title as a keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_preprocessed.loc[dataset_preprocessed['id'].isin(starred_ids), 'is_starred'] = 1\n",
    "dataset_preprocessed.loc[~dataset_preprocessed['id'].isin(starred_ids), 'is_starred'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_starred_score(data):\n",
    "    data = data.copy()\n",
    "    \n",
    "    # Starred Queries\n",
    "    queries = data[data['is_starred'] == 1]['job_title_cleaned']\n",
    "    \n",
    "    similarities = []\n",
    "    for query in queries:\n",
    "        print('START: ' + query)\n",
    "        data = encode_and_get_similarity(data, [query], ['job_title_cleaned'], ['starred_similarity'])\n",
    "        similarities.append(data['starred_similarity'])\n",
    "        \n",
    "        \n",
    "    starred_similarity = np.mean(similarities, axis=0)\n",
    "    \n",
    "    return starred_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_preprocessed['starred_similarity'] = get_starred_score(dataset_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_preprocessed['mean_similarity'] = dataset_preprocessed[['bert_similarity', 'starred_similarity']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_preprocessed[['job_title', 'is_starred', 'bert_similarity', 'starred_similarity', 'mean_similarity']].sort_values(by=['mean_similarity', 'is_starred'], ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
