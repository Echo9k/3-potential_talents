{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Guill\\Miniconda3\\envs\\a4_llm\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variable HUGGINGFACE_TOKEN set.\n",
      "Instructions successfully read!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    pipeline,\n",
    ")\n",
    "from IPython.display import display, Markdown\n",
    "import torch\n",
    "\n",
    "# Paths\n",
    "paths = {\n",
    "    'root': Path.cwd().parent,\n",
    "    'data': Path.cwd().parent / \"data\",\n",
    "    \"config\": Path.cwd().parent / \"config\"\n",
    "}\n",
    "\n",
    "# Load Hugging Face credentials\n",
    "with open(paths[\"config\"] / 'credentials.json') as f:\n",
    "    credentials = json.load(f)\n",
    "\n",
    "\n",
    "if \"HUGGINGFACE_TOKEN\" in os.environ or \"HUGGINGFACE_TOKEN\" in credentials:\n",
    "    print(\"Environment variable HUGGINGFACE_TOKEN set.\")\n",
    "\n",
    "\n",
    "# Define the file path\n",
    "file_path = paths[\"config\"] / \"instructions.txt\"\n",
    "\n",
    "try:\n",
    "    # Open the file and read its content\n",
    "    with open(file_path, 'r') as file:\n",
    "        instructions = file.read()\n",
    "        print(\"Instructions successfully read!\")\n",
    "        # print(instructions)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "# Shortlisted candidates\n",
    "try:\n",
    "    list_of_candidates = pd.read_parquet(paths['data'] / \"processed/filtered.parquet\", columns=['job_title', 'rank']).set_index(\"rank\")['job_title'].to_list()\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load parquet file: {e}. Loading CSV instead.\")\n",
    "    list_of_candidates = pd.read_csv(paths['data'] / \"processed/filtered.csv\", index_col=['rank'], usecols=['job_title'])['job_title'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:16<00:00,  8.18s/it]\n",
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model and tokenizer\n",
    "model_name = \"microsoft/Phi-3-mini-128k-instruct\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # Use GPU if available\n",
    "\n",
    "# Adjust model loading for GPU\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    device_map=device,  # Use GPU if available\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Set up the pipeline\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load system description and user prompt template from files\n",
    "with open(paths[\"config\"] / 'role_system_description.txt', 'r') as f:\n",
    "    role_system_description = f.read()\n",
    "\n",
    "with open(paths[\"config\"] / 'user_prompt_template.txt', 'r') as f:\n",
    "    user_prompt_template = f.read()\n",
    "\n",
    "with open(paths[\"config\"] / 'response_format.txt', 'r') as f:\n",
    "    response_format = f.read()\n",
    "\n",
    "with open(paths[\"config\"] / 'search_criteria.txt', 'r') as f:\n",
    "    search_criteria = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Generated Output:\n",
       "\n",
       "Based on the provided criteria, here is the evaluation and ranking of the top 5 candidates suitable for a position in Human Resources located in New York:\n",
       "\n",
       "| **Candidate**                                                                          | **Experience & Background**                                                                                                   | **Reasoning for Choosing This Candidate**                                                                                                      |\n",
       "|----------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------|\n",
       "| Aspiring human resources professional an energetic and teamfocused leader              | Demonstrates a strong commitment to HR with a focus on team leadership and motivation.                                        | Strong motivation and leadership skills make this candidate a great fit with company values emphasizing energetic and team-focused personnel.   |\n",
       "| Aspiring human resources professional passionate about helping to create an inclusive and engaging work environment  | Shows passion for inclusivity and engagement within HR, emphasizing important company values.                                 | Combined passion for inclusivity and foundational HR interest are aligned with cultural values.                                                 |\n",
       "| Aspiring human resources manager seeking internship in human resources                 | Actively seeking opportunities to gain HR experience, indicating high motivation and willingness to learn.                    | Motivated to enter HR with a focus on gaining practical experience, demonstrating alignment with company values centering on motivated learners.|\n",
       "| Experienced retail manager and aspiring human resources professional                   | Brings transferable management skills from the retail sector, suitable for HR development.                                    | Possesses transferable skills valuable for HR roles, supporting a fresh perspective into developing HR practices.                                |\n",
       "| CT Bauer College of Business graduate magna cum laude and aspiring human resources professional | Strong academic background in business and interest in HR, indicating the potential for growth in the field.                   | Academic excellence with a focus on Human Resources provides a foundation for significant potential in HR.                                       |\n",
       "\n",
       "These candidates are ranked based on demonstrated motivation, relevant experience or transferable skills, and alignment with company values. They present strong potential for contributing positively to a Human Resources role with their unique capabilities and backgrounds."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_similar_roles = 'aspiring human resources'\n",
    "location = \"New York\"\n",
    "\n",
    "# Format the user prompt using the template and parameters\n",
    "user_prompt = user_prompt_template.format(\n",
    "    location=location,\n",
    "    list_similar_roles=list_similar_roles,\n",
    "    search_criteria=search_criteria,\n",
    "    list_of_candidates=\"\\n\".join(list_of_candidates)  # Joining list elements for display\n",
    ")\n",
    "\n",
    "# Prepare messages in the format required by the model\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": role_system_description},\n",
    "    {\"role\": \"user\", \"content\": user_prompt},\n",
    "]\n",
    "\n",
    "# Generate text\n",
    "generation_args = {\n",
    "    \"max_new_tokens\": 5_000,\n",
    "    \"return_full_text\": False,\n",
    "    \"do_sample\": False,\n",
    "}\n",
    "\n",
    "output = pipe(messages, **generation_args)\n",
    "display(Markdown(f\"Generated Output:\\n\\n{output[0]['generated_text']}\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a4_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
