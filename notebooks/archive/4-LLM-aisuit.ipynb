{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Guill\\Miniconda3\\envs\\a4_llm\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variable HUGGINGFACE_TOKEN set.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  8.96s/it]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import aisuite as ai\n",
    "from pathlib import Path\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from IPython.display import display, Markdown\n",
    "import os\n",
    "import json\n",
    "\n",
    "paths = {\n",
    "    'root':Path.cwd().parent,\n",
    "    'data':Path.cwd().parent / \"data\"\n",
    "}\n",
    "\n",
    "# Load the environment variable from a file config\\credentials.json\n",
    "ai.utils.load_dotenv()\n",
    "\n",
    "with open('config/credentials.json') as f:\n",
    "    credentials = json.load(f)\n",
    "\n",
    "if \"HUGGINGFACE_TOKEN\" in os.environ or \"HUGGINGFACE_TOKEN\" in credentials:\n",
    "    print(\"Environment variable HUGGINGFACE_TOKEN set.\")\n",
    "\n",
    "model_name = \"microsoft/Phi-3-mini-128k-instruct\"\n",
    "\n",
    "if not \"model\" in locals():\n",
    "    # Load the model and tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded candidate data.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ct bauer college of business graduate magna c...</td>\n",
       "      <td>houston, texas</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>native english teacher at tech english program...</td>\n",
       "      <td>kanada</td>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aspiring human resources professional</td>\n",
       "      <td>raleigh-durham, north carolina</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>people development coordinator at not tech</td>\n",
       "      <td>denton, texas</td>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>advisory board member at celal bayar university</td>\n",
       "      <td>i̇zmir, türkiye</td>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0   ct bauer college of business graduate magna c...   \n",
       "1  native english teacher at tech english program...   \n",
       "2              aspiring human resources professional   \n",
       "3         people development coordinator at not tech   \n",
       "4    advisory board member at celal bayar university   \n",
       "\n",
       "                          location  connection  \n",
       "0                   houston, texas          85  \n",
       "1                           kanada         501  \n",
       "2  raleigh-durham, north carolina           44  \n",
       "3                    denton, texas         501  \n",
       "4                  i̇zmir, türkiye         501  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the candidate data from the parquet file\n",
    "\n",
    "try:\n",
    "\tdata = pd.read_parquet(paths['data'] / \"interim/encoded.parquet\")\n",
    "except Exception as e:\n",
    "\tprint(f\"Failed to load parquet file: {e}. Loading CSV instead.\")\n",
    "\tdata = pd.read_csv(paths['data'] / \"interim/encoded.csv\")\n",
    "print(\"Loaded candidate data.\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n",
      "`get_max_cache()` is deprecated for all Cache classes. Use `get_max_cache_shape()` instead. Calling `get_max_cache()` will raise error from v4.48\n",
      "You are not running the flash-attention implementation, expect numerical differences.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Instructions: Rank the candidates based on their job_title against our search term using cosine similarity. The higher the score, the better the match. Include the cosine similarity scores. Return the top 5 candidates in markdown format. Do not show intermediary responses, nor the reasoning, only show the final table result.\n",
       "\n",
       "search term:aspiring human resources\n",
       "\n",
       "Candidates: ['human resources generalist at scottmadden inc', 'admissions representative at community medical center long beach', 'seeking human resources position', 'aspiring human resources management student seeking an internship', 'student at westfield state university', 'aspiring human resources specialist', 'director of human resources north america groupe not tech', 'business intelligence and analytics at not techs', 'people development coordinator at not tech', 'human resources professional for the world leader in techs software', 'seeking human resources opportunities', 'seeking human resources human resourcesis and generalist positions', 'human resources generalist at schwans', 'student at humber college and aspiring human resources generalist', 'information systems specialist and programmer with a love for data and organization'] \n",
       "\n",
       "### Answer:\n",
       "\n",
       "| Rank | Candidate                                                                                   | Cosine Similarity Score |\n",
       "|------|--------------------------------------------------------------------------------------------|-------------------------|\n",
       "| 1    | human resources generalist at scottmadden inc                                             | 0.92                    |\n",
       "| 2    | aspiring human resources management student seeking an internship                        | 0.89                    |\n",
       "| 3    | human resources generalist at schwans                                                     | 0.87                    |\n",
       "| 4    | seeking human resources opportunities                                                     | 0.85                    |\n",
       "| 5    | human resources generalist at not tech                                                    | 0.83                    | \n",
       "| 6    | human resources professional for the world leader in techs software                       | 0.81                    |\n",
       "| 7    | human resources generalist at not tech                                                    | 0.79                    |\n",
       "| 8    | human resources generalist at not tech                                                    | 0.78                    |\n",
       "| 9    | human resources generalist at not tech                                                    | 0.77                    |\n",
       "| 10   | human resources generalist at not tech                                                    | 0.76                    |\n",
       "| 11   | human resources generalist at not tech                                                    | 0.75                    |\n",
       "| 12   | human resources generalist at not tech                                                    | 0.74                    |\n",
       "| 13   | human resources generalist at not tech                                                    | 0.73                    |\n",
       "| 14   | human resources generalist at not tech                                                    | 0.72                    |\n",
       "| 15   | human resources generalist at not tech                                                    | 0.71                    |\n",
       "| 16   | human resources generalist at not tech                                                    | 0.70                    |\n",
       "| 17   | human resources generalist at not tech                                                    | 0.69                    |\n",
       "| 18   | human resources generalist at not tech                                                    | 0.68                    |\n",
       "| 19   | human resources generalist at not tech                                                    | 0.67                    |\n",
       "| 20   | human resources generalist at not tech                                                    | 0.66                    |\n",
       "| 21   | human resources generalist at not tech                                                    | 0.65                    |\n",
       "| 22   | human resources generalist at not tech                                                    | 0.64                    |\n",
       "| 23   | human resources generalist at not tech                                                    | 0.63                    |\n",
       "| 24   | human resources generalist at not tech                                                    | 0.62                    |\n",
       "| 25   | human resources generalist at not tech                                                    | 0.61                    |\n",
       "| 26   | human resources generalist at"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "search_phrase = 'aspiring human resources'\n",
    "location = \"New york\"\n",
    "\n",
    "# Define the task for the model\n",
    "instructions = \"Rank the candidates based on their job_title against our search term using cosine similarity. The higher the score, the better the match. Include the cosine similarity scores. Return the top 5 candidates in markdown format. Do not show intermediary responses, nor the reasoning, only show the final table result.\"\n",
    "\n",
    "# Format the data for the model\n",
    "data_sample = data['job_title'].sample(15, random_state=42).to_list()\n",
    "\n",
    "# \n",
    "messages = f\"Instructions: {instructions}\\n\\nsearch term:{search_phrase}\\n\\nCandidates: {data_sample}\"\n",
    "\n",
    "inputs = tokenizer(messages, return_tensors=\"pt\")\n",
    "\n",
    "# Generate a response\n",
    "outputs = model.generate(**inputs, max_length=800+1)\n",
    "display(Markdown(tokenizer.decode(outputs[0], skip_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Guill\\Miniconda3\\envs\\a4_llm\\Lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:115: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: input_ids, Shape: ['batch_size', 'sequence_length'], Type: tensor(int64)\n",
      "Name: attention_mask, Shape: ['batch_size', 'total_sequence_length'], Type: tensor(int64)\n",
      "Name: past_key_values.0.key, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.0.value, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.1.key, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.1.value, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.2.key, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.2.value, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.3.key, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.3.value, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.4.key, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.4.value, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.5.key, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.5.value, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.6.key, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.6.value, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.7.key, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.7.value, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.8.key, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.8.value, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.9.key, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.9.value, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.10.key, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.10.value, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.11.key, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.11.value, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.12.key, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.12.value, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.13.key, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.13.value, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.14.key, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.14.value, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.15.key, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.15.value, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.16.key, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.16.value, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.17.key, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.17.value, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.18.key, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.18.value, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.19.key, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.19.value, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.20.key, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.20.value, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.21.key, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.21.value, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.22.key, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.22.value, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.23.key, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.23.value, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.24.key, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.24.value, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.25.key, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.25.value, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.26.key, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.26.value, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.27.key, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.27.value, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.28.key, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.28.value, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.29.key, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.29.value, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.30.key, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.30.value, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.31.key, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n",
      "Name: past_key_values.31.value, Shape: ['batch_size', 8, 'past_sequence_length', 128], Type: tensor(float16)\n"
     ]
    },
    {
     "ename": "RuntimeException",
     "evalue": "[ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Non-zero status code returned while running Cast node. Name:'InsertedPrecisionFreeCast_model.layers.10.mlp.down_proj.MatMul.weight' Status Message: bad allocation",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 46\u001b[0m\n\u001b[0;32m     43\u001b[0m onnx_inputs\u001b[38;5;241m.\u001b[39mupdate(past_key_values)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Perform inference\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monnx_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(outputs)\n",
      "File \u001b[1;32mc:\\Users\\Guill\\Miniconda3\\envs\\a4_llm\\Lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:266\u001b[0m, in \u001b[0;36mSession.run\u001b[1;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[0;32m    264\u001b[0m     output_names \u001b[38;5;241m=\u001b[39m [output\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_meta]\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_feed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m C\u001b[38;5;241m.\u001b[39mEPFail \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_fallback:\n",
      "\u001b[1;31mRuntimeException\u001b[0m: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Non-zero status code returned while running Cast node. Name:'InsertedPrecisionFreeCast_model.layers.10.mlp.down_proj.MatMul.weight' Status Message: bad allocation"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from onnxruntime import InferenceSession\n",
    "import numpy as np\n",
    "\n",
    "# Custom path to the ONNX model directory\n",
    "model_dir = \"C:/Users/Guill/.cache/huggingface/hub/models--microsoft--Phi-3-small-128k-instruct-onnx-cuda/snapshots/17f60c4b6f95cc18b4b1e0667e38490deb7d899c/cuda-fp16/\"\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "\n",
    "# Load the ONNX model\n",
    "onnx_model_path = model_dir + \"phi3-small-128k-instruct-cuda-fp16.onnx\"\n",
    "session = InferenceSession(onnx_model_path, providers=[\"CUDAExecutionProvider\", \"CPUExecutionProvider\"])\n",
    "\n",
    "# Inspect model inputs\n",
    "for input_meta in session.get_inputs():\n",
    "    print(f\"Name: {input_meta.name}, Shape: {input_meta.shape}, Type: {input_meta.type}\")\n",
    "\n",
    "# Prepare the input text\n",
    "input_text = \"Rank the candidates based on their qualifications.\"\n",
    "inputs = tokenizer(input_text, return_tensors=\"np\")\n",
    "\n",
    "# Correct dimensions for past_key_values\n",
    "num_layers = 32  # Number of layers in the transformer\n",
    "num_heads = 8    # Number of attention heads\n",
    "seq_len = 1      # Sequence length for past key values\n",
    "hidden_size_per_head = 128  # Hidden size per attention head\n",
    "\n",
    "past_key_values = {\n",
    "    f\"past_key_values.{i}.key\": np.zeros((1, num_heads, seq_len, hidden_size_per_head), dtype=np.float16)\n",
    "    for i in range(num_layers)\n",
    "}\n",
    "past_key_values.update({\n",
    "    f\"past_key_values.{i}.value\": np.zeros((1, num_heads, seq_len, hidden_size_per_head), dtype=np.float16)\n",
    "    for i in range(num_layers)\n",
    "})\n",
    "\n",
    "# Combine input IDs, attention mask, and past_key_values\n",
    "onnx_inputs = {\n",
    "    \"input_ids\": inputs[\"input_ids\"].astype(np.int64),  # Ensure input_ids is int64\n",
    "    \"attention_mask\": inputs[\"attention_mask\"].astype(np.int64),  # Ensure attention_mask is int64\n",
    "}\n",
    "onnx_inputs.update(past_key_values)\n",
    "\n",
    "# Perform inference\n",
    "outputs = session.run(None, onnx_inputs)\n",
    "print(outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded candidate data.\n",
      "                                           job_title  \\\n",
      "0   ct bauer college of business graduate magna c...   \n",
      "1  native english teacher at tech english program...   \n",
      "2              aspiring human resources professional   \n",
      "3         people development coordinator at not tech   \n",
      "4    advisory board member at celal bayar university   \n",
      "\n",
      "                          location  connection  \n",
      "0                   houston, texas          85  \n",
      "1                           kanada         501  \n",
      "2  raleigh-durham, north carolina           44  \n",
      "3                    denton, texas         501  \n",
      "4                  i̇zmir, türkiye         501  \n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /v1/chat/completions (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000017794D41210>: Failed to establish a new connection: [WinError 10061] No se puede establecer una conexión ya que el equipo de destino denegó expresamente dicha conexión'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Guill\\Miniconda3\\envs\\a4_llm\\Lib\\site-packages\\urllib3\\connection.py:199\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 199\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Guill\\Miniconda3\\envs\\a4_llm\\Lib\\site-packages\\urllib3\\util\\connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Guill\\Miniconda3\\envs\\a4_llm\\Lib\\site-packages\\urllib3\\util\\connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[1;32m---> 73\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m: [WinError 10061] No se puede establecer una conexión ya que el equipo de destino denegó expresamente dicha conexión",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Guill\\Miniconda3\\envs\\a4_llm\\Lib\\site-packages\\urllib3\\connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Guill\\Miniconda3\\envs\\a4_llm\\Lib\\site-packages\\urllib3\\connectionpool.py:495\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 495\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce_content_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Guill\\Miniconda3\\envs\\a4_llm\\Lib\\site-packages\\urllib3\\connection.py:441\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mputheader(header, value)\n\u001b[1;32m--> 441\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;66;03m# If we're given a body we start sending that in chunks.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Guill\\Miniconda3\\envs\\a4_llm\\Lib\\http\\client.py:1298\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1298\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Guill\\Miniconda3\\envs\\a4_llm\\Lib\\http\\client.py:1058\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1057\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1058\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1061\u001b[0m \n\u001b[0;32m   1062\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Guill\\Miniconda3\\envs\\a4_llm\\Lib\\http\\client.py:996\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[1;32m--> 996\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    997\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Guill\\Miniconda3\\envs\\a4_llm\\Lib\\site-packages\\urllib3\\connection.py:279\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 279\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;66;03m# If we're tunneling it means we're connected to our proxy.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Guill\\Miniconda3\\envs\\a4_llm\\Lib\\site-packages\\urllib3\\connection.py:214\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 214\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[0;32m    215\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    216\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;66;03m# Audit hooks are only available in Python 3.8+\u001b[39;00m\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x0000017794D41210>: Failed to establish a new connection: [WinError 10061] No se puede establecer una conexión ya que el equipo de destino denegó expresamente dicha conexión",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Guill\\Miniconda3\\envs\\a4_llm\\Lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\Guill\\Miniconda3\\envs\\a4_llm\\Lib\\site-packages\\urllib3\\connectionpool.py:843\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    841\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[1;32m--> 843\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    846\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[1;32mc:\\Users\\Guill\\Miniconda3\\envs\\a4_llm\\Lib\\site-packages\\urllib3\\util\\retry.py:519\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    518\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[1;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    521\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /v1/chat/completions (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000017794D41210>: Failed to establish a new connection: [WinError 10061] No se puede establecer una conexión ya que el equipo de destino denegó expresamente dicha conexión'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 30\u001b[0m\n\u001b[0;32m     24\u001b[0m payload \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicrosoft/Phi-3-small-128k-instruct-onnx-cuda\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages\n\u001b[0;32m     27\u001b[0m }\n\u001b[0;32m     28\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m---> 30\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel response:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Guill\\Miniconda3\\envs\\a4_llm\\Lib\\site-packages\\requests\\api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[1;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Guill\\Miniconda3\\envs\\a4_llm\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Guill\\Miniconda3\\envs\\a4_llm\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\Guill\\Miniconda3\\envs\\a4_llm\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\Guill\\Miniconda3\\envs\\a4_llm\\Lib\\site-packages\\requests\\adapters.py:700\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    696\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, _SSLError):\n\u001b[0;32m    697\u001b[0m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[0;32m    698\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m--> 700\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[1;31mConnectionError\u001b[0m: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /v1/chat/completions (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000017794D41210>: Failed to establish a new connection: [WinError 10061] No se puede establecer una conexión ya que el equipo de destino denegó expresamente dicha conexión'))"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Load the candidate data from the parquet file\n",
    "data_path = \"../data/interim/encoded.parquet\"\n",
    "data = pd.read_parquet(data_path)\n",
    "print(\"Loaded candidate data.\")\n",
    "print(data.head())\n",
    "\n",
    "# Define the task for the model\n",
    "instructions = \"Rank the candidates based on their job_title, location, and connection fields. Assign a fit score between 1 (low fit) and 10 (high fit) based on relevance to the desired profile.\"\n",
    "\n",
    "# Format the data for the model\n",
    "data_sample = data[['job_title', 'location', 'connection']].head(5).to_dict(orient='records')\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a ranking assistant for hiring. Evaluate candidates based on the following instructions.\"},\n",
    "    {\"role\": \"user\", \"content\": f\"Instructions: {instructions}\\n\\nCandidates:\\n{data_sample}\"},\n",
    "]\n",
    "\n",
    "# Send a request to the locally running vLLM server\n",
    "url = \"http://localhost:8000/v1/chat/completions\"\n",
    "payload = {\n",
    "    \"model\": \"microsoft/Phi-3-small-128k-instruct-onnx-cuda\",\n",
    "    \"messages\": messages\n",
    "}\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=payload)\n",
    "if response.status_code == 200:\n",
    "    print(\"Model response:\")\n",
    "    response_text = response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    print(response_text)\n",
    "else:\n",
    "    print(f\"Failed to get response: {response.status_code}, {response.text}\")\n",
    "\n",
    "# Process the response (if needed) and integrate the scores back into the dataset\n",
    "# This assumes the model returns a list of scores corresponding to the candidates\n",
    "# (Implement response parsing logic here, if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Add a 'fit_score' column based on dummy logic for demonstration\n",
    "data['fit_score'] = [8, 7, 5, 6, 9]  # Replace with actual parsed scores\n",
    "\n",
    "print(data.head())\n",
    "\n",
    "# Save the ranked data for further analysis\n",
    "output_path = \"data/interim/ranked_candidates.parquet\"\n",
    "data.to_parquet(output_path, index=False)\n",
    "print(f\"Ranked candidates saved to {output_path}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a4_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
