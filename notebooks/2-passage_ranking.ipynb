{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "24a272a1",
      "metadata": {},
      "source": [
        "# Passage Ranking\n",
        "\n",
        "This notebook evaluates and ranks candidates' fit for specific roles based on similarity scores. By leveraging machine learning and automation, we aim to streamline the recruitment process, reducing manual efforts and enhancing decision-making quality."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a92f754",
      "metadata": {},
      "source": [
        "## Overview\n",
        "\n",
        "This step focuses on testing and optimizing the performance of our candidate ranking system. We:\n",
        "\n",
        "1. Set up the environment and load the necessary data and libraries.\n",
        "2. Compute similarity scores between job titles and predefined phrases.\n",
        "3. Filter, rank, and aggregate results to identify the best matches.\n",
        "4. Store the results for further analysis and integration."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "228ec44d",
      "metadata": {},
      "source": [
        "## Set up\n",
        "\n",
        "### Loading Libraries and Setting Paths\n",
        "\n",
        "We initialize the working environment, import libraries, and set up paths for data and configurations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8ef6727d",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/home/sagemaker-user/3-potential_talents'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    root_dir = \"/content/drive/MyDrive/wdir/repos/Apziva/3-potential_talents/\"\n",
        "    os.getcwd()\n",
        "\n",
        "except ImportError:\n",
        "    while 'potential_talents' not in os.listdir('.'):\n",
        "        os.chdir('..')\n",
        "        root_dir=os.getcwd()\n",
        "    \n",
        "    # append term_deposit to system to import custom functions\n",
        "    sys.path.append('.')\n",
        "    \n",
        "%pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cac8e422",
      "metadata": {},
      "source": [
        "### Loading Data and API Setup\n",
        "\n",
        "Here, we load the encoded job titles and configure the API credentials for similarity computations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ff7fc532",
      "metadata": {
        "tags": [
          "config"
        ]
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import toml\n",
        "import json\n",
        "import requests\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "data_path = Path(\"data\")\n",
        "data = pd.read_parquet(data_path  / \"interim\" / \"encoded.parquet\", columns=['job_title'])\n",
        "\n",
        "credentials_path = Path(root_dir) / \"config\" / \"credentials.json\"\n",
        "with open(credentials_path, \"r\") as file:\n",
        "    credentials = json.load(file)\n",
        "\n",
        "# Define multiple search phrases for comparison\n",
        "phrases_path = Path(root_dir) / \"config\" / \"search_phrases.toml\"\n",
        "phrases = toml.load(phrases_path)['search_phrases']\n",
        "\n",
        "# API and credentials setup\n",
        "API_URL = \"https://api-inference.huggingface.co/models/sentence-transformers/msmarco-distilbert-base-tas-b\"\n",
        "headers = {\"Authorization\": f\"Bearer {credentials['HUGGINGFACE_TOKEN']}\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a80d745",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Core Functions\n",
        "\n",
        "### Query Function\n",
        "\n",
        "The `query` function sends POST requests to the Hugging Face inference API to compute similarity scores.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "31226719",
      "metadata": {},
      "outputs": [],
      "source": [
        "def query(payload):\n",
        "    \"\"\"Send a POST request to Hugging Face inference API.\"\"\"\n",
        "    response = requests.post(API_URL, headers=headers, json=payload)\n",
        "    if response.status_code == 200:\n",
        "        return response.json()  # Assuming the API returns a JSON response\n",
        "    else:\n",
        "        raise Exception(f\"API Error: {response.status_code} {response.text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8a1598a",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### Computing Similarities\n",
        "\n",
        "This function computes the similarity scores between multiple predefined phrases and job titles.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d1ca1f80",
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_similarities(data, phrases):\n",
        "    \"\"\"Compute similarities between multiple phrases and job titles.\"\"\"\n",
        "    similarity_matrix = []\n",
        "    \n",
        "    for phrase in phrases:\n",
        "        payload = {\n",
        "            \"inputs\": {\n",
        "                \"source_sentence\": phrase,\n",
        "                \"sentences\": data['job_title'].tolist()\n",
        "            }\n",
        "        }\n",
        "        response = query(payload)\n",
        "        \n",
        "        if isinstance(response, dict) and 'similarities' in response:\n",
        "            scores = response['similarities']\n",
        "        elif isinstance(response, list):\n",
        "            scores = response\n",
        "        else:\n",
        "            raise TypeError(f\"Unexpected response format: {response}\")\n",
        "        \n",
        "        similarity_matrix.append(scores)\n",
        "    \n",
        "    return np.array(similarity_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10a1605f",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### Retry Mechanism for Robustness\n",
        "\n",
        "Added a retry mechanism to handle API timeouts or delays.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "960e9bb6",
      "metadata": {},
      "outputs": [],
      "source": [
        "def query_with_retry(payload, retries=5, delay=20):\n",
        "    \"\"\"Send a POST request to Hugging Face inference API with retry mechanism.\"\"\"\n",
        "    for attempt in range(retries):\n",
        "        response = requests.post(API_URL, headers=headers, json=payload)\n",
        "        if response.status_code == 200:\n",
        "            return response.json()\n",
        "        elif response.status_code == 503:\n",
        "            print(f\"Model is loading, retrying in {delay} seconds...\")\n",
        "            time.sleep(delay)\n",
        "        else:\n",
        "            raise Exception(f\"API Error: {response.status_code} {response.text}\")\n",
        "    raise Exception(\"Max retries exceeded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b8e29bb3",
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_similarities_with_retry(data, phrases):\n",
        "    \"\"\"Compute similarities between multiple phrases and job titles with retry mechanism.\"\"\"\n",
        "    similarity_matrix = []\n",
        "    \n",
        "    for phrase in phrases:\n",
        "        payload = {\n",
        "            \"inputs\": {\n",
        "                \"source_sentence\": phrase,\n",
        "                \"sentences\": data['job_title'].tolist()\n",
        "            }\n",
        "        }\n",
        "        response = query_with_retry(payload)\n",
        "        \n",
        "        # Debug the response structure\n",
        "        if isinstance(response, dict) and 'similarities' in response:\n",
        "            scores = response['similarities']\n",
        "        elif isinstance(response, list):  # Sometimes APIs return a list of scores\n",
        "            scores = response\n",
        "        else:\n",
        "            raise TypeError(f\"Unexpected response format: {response}\")\n",
        "        \n",
        "        similarity_matrix.append(scores)\n",
        "    \n",
        "    return np.array(similarity_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c23fbb1",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### Adding Similarity Scores to the DataFrame\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "0a1db522",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model is loading, retrying in 20 seconds...\n"
          ]
        }
      ],
      "source": [
        "# Compute similarity scores\n",
        "similarity_matrix = compute_similarities_with_retry(data, phrases)\n",
        "\n",
        "# Add scores for each phrase to the DataFrame\n",
        "for i, phrase in enumerate(phrases):\n",
        "    data[f\"similarity_to_{phrase}\"] = similarity_matrix[i]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb97d129",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Filtering and Ranking\n",
        "\n",
        "This section filters and ranks job titles based on their similarity scores to each phrase.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "7c97b0ce",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filter and rank results for each phrase\n",
        "filtered_results = []\n",
        "for phrase in phrases:\n",
        "    filtered = (\n",
        "        data\n",
        "        .sort_values(f\"similarity_to_{phrase}\", ascending=False)\n",
        "    )\n",
        "    filtered['matching_phrase'] = phrase\n",
        "    filtered_results.append(filtered)\n",
        "\n",
        "# Combine filtered results into a single DataFrame\n",
        "final_result = pd.concat(filtered_results).drop_duplicates().reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75c8e635",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Aggregation and Final Rankings\n",
        "\n",
        "We compute an aggregate fit score to rank the job titles effectively.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "f71a3bcb",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>job_title</th>\n",
              "      <th>matching_phrase</th>\n",
              "      <th>fit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>254</th>\n",
              "      <td>student</td>\n",
              "      <td>talent acquisition assistant</td>\n",
              "      <td>0.626730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>365</th>\n",
              "      <td>aspiring human resources manager seeking inter...</td>\n",
              "      <td>hr trainee</td>\n",
              "      <td>0.720167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>senior human resources business partner at not...</td>\n",
              "      <td>recruitment coordinator</td>\n",
              "      <td>0.698470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>460</th>\n",
              "      <td>student</td>\n",
              "      <td>junior hr specialist</td>\n",
              "      <td>0.626730</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             job_title  \\\n",
              "254                                            student   \n",
              "365  aspiring human resources manager seeking inter...   \n",
              "302  senior human resources business partner at not...   \n",
              "460                                            student   \n",
              "\n",
              "                  matching_phrase       fit  \n",
              "254  talent acquisition assistant  0.626730  \n",
              "365                    hr trainee  0.720167  \n",
              "302       recruitment coordinator  0.698470  \n",
              "460          junior hr specialist  0.626730  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_result = final_result.assign(\n",
        "    fit=final_result.iloc[:, 1:-1].median(axis=1)-final_result.iloc[:, 1:-1].std(axis=1)\n",
        "    ).sort_values('fit', ascending=False).iloc[:, [0,-2,-1]]\n",
        "final_result.sample(4, random_state=27)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1511f21",
      "metadata": {},
      "source": [
        "Group and save the results for downstream analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "f7a28373",
      "metadata": {},
      "outputs": [],
      "source": [
        "grouped_results = pd.DataFrame(\n",
        "    final_result.groupby('job_title')[\"fit\"].mean()\\\n",
        "    .sort_values(ascending=False)\n",
        "    )\n",
        "grouped_results.to_parquet(data_path / \"processed\" / \"grouped_results.parquet\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "talent",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
